{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "# You can write up to 20GB to the current directory that gets preserved as output when you create a version using \"Save & Run All\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hateful Meme Detection**\n",
    "\n",
    "**CHINTHA YETHI RAJ**\n",
    "**210108013**\n",
    "\n",
    "In recent years, the proliferation of hateful content on social media platforms has emerged as a significant concern, necessitating robust detection mechanisms to safeguard online communities. This project aims to develop an advanced system for the detection of hateful memes, which are a particularly insidious form of harmful content combining images and text to convey hate speech or discrimination. The proposed solution leverages state-of-the-art machine learning techniques, including convolutional neural networks (CNNs) for image analysis and transformer-based models for natural language processing (NLP). By integrating these methodologies, the system can accurately interpret and assess the multimodal content of memes.\n",
    "\n",
    "The core of the project involves creating a comprehensive dataset of labeled hateful and non-hateful memes, ensuring diversity in both visual and textual components to enhance the model's generalizability. We employ a multi-stage training process where the CNNs extract visual features, and the transformer models analyze textual data, followed by a fusion mechanism to combine these features for final classification. Additionally, we implement techniques to address challenges such as context variability, sarcasm, and subtlety in hate speech, which are prevalent in memes.\n",
    "\n",
    "Performance evaluation of the system is conducted using standard metrics such as accuracy, precision, recall, and F1-score, along with a comparative analysis against existing state-of-the-art approaches. Preliminary results demonstrate the effectiveness of our model in accurately detecting hateful memes, highlighting its potential for deployment in real-world social media monitoring tools.\n",
    "\n",
    "The project's contributions include not only a robust detection model but also insights into the challenges and nuances of multimodal hate speech detection. By enhancing the ability to automatically identify and mitigate the spread of hateful content, this project aims to contribute significantly to the creation of safer online environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "[Problem](#problem)   \n",
    "[Data Understanding](#data_understanding)   \n",
    "[Data Preparation](#data_preparation)   \n",
    "[Modeling](#modeling)   \n",
    "[Evaluation](#evaluation)   \n",
    "[References](#references)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem <a class=\"anchor\" id=\"problem\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rise of memes on social media has turned them into influential communication tools. Unfortunately, this medium is also being used to spread hate speech and harmful content. Detecting hateful memes is challenging due to their multimodal nature, where harmful intent can be subtly embedded in both images and text. Traditional detection systems focusing only on text or images are insufficient for understanding these nuances.\n",
    "\n",
    "Key Questions Addressed in the Project\n",
    "\n",
    "1. How can we effectively detect hate speech in memes?\n",
    "\n",
    "    Memes require an integrated approach to understand the interplay between visual and textual elements.\n",
    "    \n",
    "2. What machine learning models and techniques are most effective for this task?\n",
    "\n",
    "    Exploring and combining CNNs for image processing and transformers for text analysis to create an accurate classification system.\n",
    "    \n",
    "3. How can we create a comprehensive dataset for training and evaluation?\n",
    "\n",
    "    Collecting and annotating a diverse set of memes reflecting real-world variability for robust model training.\n",
    "    \n",
    "4. What challenges arise in detecting subtle and context-dependent hate speech in memes?\n",
    "\n",
    "    Addressing issues like sarcasm, irony, and cultural references that obscure harmful intent.\n",
    "    \n",
    "5. How can we evaluate the performance of the detection system?\n",
    "\n",
    "    Using metrics like accuracy, precision, recall, and F1-score, and comparing results with existing methods.\n",
    "    \n",
    "6. What are the ethical considerations and potential biases in detecting hateful content?\n",
    "\n",
    "    Ensuring fairness, avoiding censorship of benign content, and addressing biases in training data.\n",
    "    \n",
    "This project aims to develop an effective hateful meme detection system to enhance online safety and inclusivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding<a class=\"anchor\" id=\"data_understanding\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will utilize the Facebook Hateful Memes Detection Challenge dataset. This dataset is specifically designed for multimodal hate speech detection and includes a diverse collection of memes, combining images and associated text. Each meme is labeled as either hateful or non-hateful. The dataset provides a balanced mix of various cultural references and contexts, ensuring comprehensive coverage for training and evaluation. By leveraging this dataset, we aim to build and validate a robust system capable of accurately detecting hateful content in memes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import random\n",
    "import tarfile\n",
    "import tempfile\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchvision"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data_dir = \"/kaggle/input/data-intensive/data/\"\n",
    "train_path = data_dir + \"train.jsonl\"\n",
    "dev_path = data_dir  + \"dev.jsonl\"\n",
    "test_path = data_dir + \"test.jsonl\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_samples_frame = pd.read_json(train_path, lines=True)\n",
    "val_samples_frame = pd.read_json(dev_path, lines=True)\n",
    "train_samples_frame.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_samples_frame.label.value_counts()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_samples_frame['length'] = train_samples_frame['text'].apply(len)\n",
    "# Define the number of bins\n",
    "num_bins = 3\n",
    "\n",
    "# Create bins automatically\n",
    "train_samples_frame['length_bins'] = pd.cut(train_samples_frame['length'], bins=num_bins)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Using Seaborn for better aesthetics\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='length_bins', data=train_samples_frame, palette='viridis')\n",
    "\n",
    "plt.title('Number of Sentences in Length Ranges')\n",
    "plt.xlabel('Sentence Length Range')\n",
    "plt.ylabel('Number of Sentences')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "max_length = train_samples_frame['length'].max()\n",
    "print(\"Maximum Length:\", max_length)\n",
    "median_length = train_samples_frame['length'].median()\n",
    "print(\"Median Length:\", median_length)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_samples_frame"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation<a class=\"anchor\" id=\"data_preparation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain what kind of data transformations, feature selection and/or engineering you will perform."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_samples_frame = train_samples_frame[train_samples_frame['length'] < 64]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_samples_frame = train_samples_frame.sample(2000)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_texts = list(train_samples_frame['text'])\n",
    "val_texts = list(val_samples_frame['text'])\n",
    "train_labels = list(train_samples_frame['label'])\n",
    "val_labels = list(val_samples_frame['label'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "train_images = []\n",
    "val_images = []\n",
    "\n",
    "for i in list(val_samples_frame['img']):\n",
    "    path = data_dir + i\n",
    "    img = load_img(path, target_size=(128, 128))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array /= 255.0  # Normalize pixel values\n",
    "    val_images.append(img_array)\n",
    "\n",
    "for i in list(train_samples_frame['img']):\n",
    "    path = data_dir + i\n",
    "    img = load_img(path, target_size=(128, 128))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array /= 255.0  # Normalize pixel values\n",
    "    train_images.append(img_array)\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "val_images = np.array(val_images)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, GlobalAveragePooling2D,Flatten\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    inputs = tokenizer(texts, return_tensors=\"tf\", padding=True, truncation=True, max_length=128)\n",
    "    outputs = bert_model(inputs)\n",
    "    outputs = outputs.last_hidden_state[:, 0, :]  # Use the [CLS] token embedding\n",
    "    return outputs\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_text_embeddings = get_bert_embeddings(train_texts)\n",
    "val_text_embeddings = get_bert_embeddings(val_texts)\n",
    "train_text_embeddings = np.array(train_text_embeddings)\n",
    "val_text_embeddings = np.array(val_text_embeddings)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_text_embeddings.shape"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_labels = np.array(train_labels)\n",
    "val_labels = np.array(val_labels)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling<a class=\"anchor\" id=\"modeling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, GlobalAveragePooling2D,Flatten, Dropout\n",
    "\n",
    "# Load pre-trained InceptionResNetV2 model, exclude top layers\n",
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(128 , 128, 3))\n",
    "\n",
    "# Custom model combining InceptionResNetV2 and BERT embeddings\n",
    "image_input = base_model.input\n",
    "x = base_model(image_input)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "text_input = Input((768,))\n",
    "text_input = Flatten()(text_input)\n",
    "\n",
    "combined = Concatenate()([x, text_input])\n",
    "\n",
    "x_last = Dense(1024, activation = 'relu')(combined)\n",
    "x_last = Dense(512, activation = 'relu')(x_last)\n",
    "x_last = Dropout(0.5)(x_last)\n",
    "x_last = Dense(256, activation = 'relu')(x_last)\n",
    "x_last = Dense(128, activation = 'relu')(x_last)\n",
    "x_last = Dropout(0.5)(x_last)\n",
    "predictions = Dense(2, activation='softmax')(x_last)\n",
    "\n",
    "\n",
    "# Define the final model\n",
    "model = Model(inputs=[image_input, text_input], outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train the model\n",
    "model.fit([train_images, train_text_embeddings], train_labels, epochs=20, batch_size=32,validation_data=([val_images, val_text_embeddings], val_labels))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "predictions = model.predict([val_images, val_text_embeddings])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "predictions = np.argmax(predictions, axis=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(val_labels, predictions)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(val_labels, predictions, target_names = ['non_hateful','hateful']))\n",
    "cm = confusion_matrix(val_labels, predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['non_hateful','hateful'], yticklabels= ['non_hateful','hateful'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}