{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hateful Meme Detection: The Challenge of Multimodal Learning\n",
    "### By Chintha Yethi Raj\n",
    "\n",
    "![Blog Header](https://i.ibb.co/c6vvvmt/hateful-meme-detection-header.jpg)\n",
    "*Image: Conceptual illustration of hateful meme detection showing multimodal analysis*\n",
    "\n",
    "## Motivation\n",
    "\n",
    "In today's digital landscape, memes have become a dominant form of communication and cultural expression. While many memes are harmless and humorous, some are created with malicious intent to spread hate, prejudice, and division. These **hateful memes** pose a unique challenge for content moderation systems because they combine text and images in nuanced ways that require understanding both modalities and their interaction.\n",
    "\n",
    "I was drawn to this topic for several compelling reasons:\n",
    "\n",
    "1. **Social Impact**: Hateful content online contributes to real-world harm. Building systems that can detect and mitigate such content can help create safer online communities.\n",
    "\n",
    "2. **Technical Challenge**: Hateful meme detection represents one of the frontier problems in multimodal learning. Text alone might seem benign, and an image alone might appear harmless, but together they can convey hateful messaging.\n",
    "\n",
    "3. **Research Advancements**: Recent breakthroughs in multimodal learning make this an exciting time to explore this problem, with new architectures that can process and understand cross-modal relationships.\n",
    "\n",
    "The Kaggle notebook created by Alihan Sagoz provides an excellent exploration of this challenge, and I wanted to unpack its insights for a broader audience while connecting it to the larger field of multimodal learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Perspective on Multimodal Learning\n",
    "\n",
    "### Evolution of Multimodal Learning\n",
    "\n",
    "Multimodal learning has undergone significant evolution over the past decade. Here's a brief timeline of key developments:\n",
    "\n",
    "- **Early Days (pre-2015)**: Separate models for text and image processing with manual feature engineering and simple fusion techniques.\n",
    "\n",
    "- **Mid-2010s**: The rise of deep learning led to more sophisticated unimodal models (CNNs for images, RNNs/LSTMs for text), but multimodal fusion remained relatively simple.\n",
    "\n",
    "- **Late 2010s**: Introduction of attention mechanisms and transformer architectures revolutionized NLP (BERT, 2018) and later vision (Vision Transformers, 2020).\n",
    "\n",
    "- **2019-2020**: Specialized multimodal architectures emerged, such as ViLBERT, VisualBERT, and LXMERT, which could learn joint representations across modalities.\n",
    "\n",
    "- **2021-Present**: Large-scale pre-trained multimodal models like CLIP, DALL-E, Flamingo, and multimodal LLMs have dramatically improved the state of the art.\n",
    "\n",
    "### Hateful Meme Detection in Context\n",
    "\n",
    "The field of hateful meme detection specifically gained prominence with Facebook's Hateful Memes Challenge in 2020. This challenge highlighted several key aspects of the problem:\n",
    "\n",
    "1. **Multimodal Reasoning**: The challenge demonstrated that successful detection requires understanding the relationship between text and image, not just processing them independently.\n",
    "\n",
    "2. **Adversarial Examples**: The dataset was designed to include \"benign confounders\" – memes that would be misclassified if only one modality was considered.\n",
    "\n",
    "3. **Social Context**: Understanding hateful content often requires cultural, social, and contextual knowledge beyond what's explicitly in the data.\n",
    "\n",
    "Recent approaches have built upon multimodal foundation models, using techniques like contrastive learning, prompt engineering, and fine-tuning to adapt general-purpose models to this specific task. The field continues to advance with research into more robust architectures that can handle the nuanced, context-dependent nature of hateful content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Learnings from the Kaggle Notebook\n",
    "\n",
    "The [Kaggle notebook by Alihan Sagoz](https://www.kaggle.com/code/alihansagoz/hateful-meme-detection) offers several valuable insights into tackling the hateful meme detection problem. Here are the key learnings:\n",
    "\n",
    "### 1. Problem Formulation\n",
    "\n",
    "The problem is framed as a binary classification task: determining whether a meme (image-text pair) is hateful or not. This seemingly simple formulation masks significant complexity:\n",
    "\n",
    "- Memes combine visual and textual elements where meaning emerges from their interaction\n",
    "- The same image with different text (or vice versa) can completely change the meaning\n",
    "- Cultural and contextual understanding is often necessary\n",
    "\n",
    "### 2. Data Understanding\n",
    "\n",
    "The notebook uses the Facebook Hateful Memes dataset, which contains 10,000+ multimodal examples specifically designed to be challenging. Key aspects include:\n",
    "\n",
    "- Carefully constructed \"benign confounders\" that require multimodal understanding\n",
    "- Balanced class distribution (hateful vs. non-hateful)\n",
    "- High-quality annotations following clear guidelines on what constitutes hate speech\n",
    "\n",
    "### 3. Multimodal Architecture Design\n",
    "\n",
    "The notebook explores a two-branch approach:\n",
    "\n",
    "- **Image Branch**: Uses pre-trained vision models (ResNet, EfficientNet) to extract visual features\n",
    "- **Text Branch**: Employs transformer-based language models (BERT, RoBERTa) for text understanding\n",
    "- **Fusion Strategy**: Combines features from both branches through concatenation followed by MLP layers\n",
    "\n",
    "This approach allows the model to learn both unimodal representations and their interactions.\n",
    "\n",
    "### 4. Training Strategies\n",
    "\n",
    "Several effective training strategies emerge:\n",
    "\n",
    "- **Transfer Learning**: Starting with pre-trained vision and language models rather than training from scratch\n",
    "- **Fine-Tuning**: Carefully unfreezing and tuning different components of the model\n",
    "- **Regularization**: Using dropout, learning rate scheduling, and early stopping to prevent overfitting\n",
    "- **Data Augmentation**: Employing techniques like slight image transformations to increase effective dataset size\n",
    "\n",
    "### 5. Evaluation and Interpretation\n",
    "\n",
    "The notebook emphasizes thoughtful evaluation:\n",
    "\n",
    "- Using metrics beyond accuracy (AUC-ROC, precision, recall, F1) given the societal implications\n",
    "- Analyzing model failures to understand where the multimodal reasoning breaks down\n",
    "- Considering both false positives and false negatives in the context of content moderation\n",
    "\n",
    "These learnings highlight that effective hateful meme detection requires not just advanced multimodal architectures, but also careful problem formulation, dataset curation, and evaluation methodologies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code and Experimentation\n",
    "\n",
    "Let's walk through some key code components from the Kaggle notebook to demonstrate the technical implementation of hateful meme detection. I'll highlight the most instructive parts with explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Loading and Exploration\n",
    "\n",
    "First, let's examine how to load and explore the dataset structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code example - not for execution in this blog post\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Load the dataset (paths would be based on your environment)\n",
    "def load_data(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "# Example of what loading would look like\n",
    "# train_df = load_data('/path/to/train.json')\n",
    "# dev_df = load_data('/path/to/dev.json')\n",
    "\n",
    "# Sample dataframe structure\n",
    "sample_data = [\n",
    "    {\"id\": 1, \"img\": \"img1.png\", \"text\": \"Sample text for meme 1\", \"label\": 0},\n",
    "    {\"id\": 2, \"img\": \"img2.png\", \"text\": \"Sample text for meme 2\", \"label\": 1},\n",
    "]\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "print(sample_df.head())\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"Class distribution: {sample_df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualizing Sample Memes\n",
    "\n",
    "To understand the data better, we would typically visualize some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code example - not for execution in this blog post\n",
    "def display_meme(df, idx, img_dir):\n",
    "    row = df.iloc[idx]\n",
    "    img_path = os.path.join(img_dir, row['img'])\n",
    "    \n",
    "    # Display image with text overlay\n",
    "    img = Image.open(img_path)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Text: {row['text']}\\nLabel: {'Hateful' if row['label'] == 1 else 'Non-hateful'}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (not executed)\n",
    "# display_meme(train_df, 0, '/path/to/images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multimodal Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code example - not for execution in this blog post\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "# Image feature extraction\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use a pre-trained CNN as backbone\n",
    "        resnet = models.resnet50(pretrained=True)\n",
    "        # Remove the classification head\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        # Feature dimension\n",
    "        self.out_dim = 2048\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract features\n",
    "        x = self.backbone(x)\n",
    "        # Flatten\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "# Text feature extraction\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use pre-trained BERT\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        # Feature dimension\n",
    "        self.out_dim = 768\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get BERT embeddings\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Use the [CLS] token representation\n",
    "        return outputs.pooler_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multimodal Fusion and Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code example - not for execution in this blog post\n",
    "class HatefulMemeClassifier(nn.Module):\n",
    "    def __init__(self, image_encoder, text_encoder):\n",
    "        super().__init__()\n",
    "        self.image_encoder = image_encoder\n",
    "        self.text_encoder = text_encoder\n",
    "        \n",
    "        # Fusion and classification layers\n",
    "        combined_dim = image_encoder.out_dim + text_encoder.out_dim\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(combined_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        # Extract features from both modalities\n",
    "        img_features = self.image_encoder(images)\n",
    "        text_features = self.text_encoder(input_ids, attention_mask)\n",
    "        \n",
    "        # Concatenate features (simple fusion strategy)\n",
    "        combined = torch.cat([img_features, text_features], dim=1)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(combined)\n",
    "        return logits.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code example - not for execution in this blog post\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    best_val_auc = 0.0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_auc': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].float().to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].float().to(device)\n",
    "                \n",
    "                outputs = model(images, input_ids, attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                \n",
    "                all_preds.extend(probs.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        val_auc = roc_auc_score(all_labels, all_preds)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "              f\"Train Loss: {train_loss/len(train_loader):.4f} - \"\n",
    "              f\"Val Loss: {val_loss/len(val_loader):.4f} - \"\n",
    "              f\"Val AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "            print(f\"Saved new best model with AUC: {val_auc:.4f}\")\n",
    "        \n",
    "        # Update history\n",
    "        history['train_loss'].append(train_loss/len(train_loader))\n",
    "        history['val_loss'].append(val_loss/len(val_loader))\n",
    "        history['val_auc'].append(val_auc)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Visualizing Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code example - not for execution in this blog post\n",
    "def plot_training_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train')\n",
    "    plt.plot(history['val_loss'], label='Validation')\n",
    "    plt.title('Loss vs. Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation AUC\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['val_auc'])\n",
    "    plt.title('Validation AUC vs. Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('AUC')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# Example usage (not executed)\n",
    "# plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Error Analysis\n",
    "\n",
    "Let's also look at how we might analyze errors to improve our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a code example - not for execution in this blog post\n",
    "def analyze_errors(model, test_loader, img_dir, threshold=0.5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    false_positives = []\n",
    "    false_negatives = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].float().to(device)\n",
    "            meme_ids = batch['id']\n",
    "            \n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > threshold).float()\n",
    "            \n",
    "            # Collect false positives (predicted hateful but actually not)\n",
    "            fp_indices = (preds == 1) & (labels == 0)\n",
    "            for idx in torch.where(fp_indices)[0]:\n",
    "                false_positives.append({\n",
    "                    'id': meme_ids[idx],\n",
    "                    'prob': probs[idx].item(),\n",
    "                    'text': batch['text'][idx]\n",
    "                })\n",
    "            \n",
    "            # Collect false negatives (predicted not hateful but actually is)\n",
    "            fn_indices = (preds == 0) & (labels == 1)\n",
    "            for idx in torch.where(fn_indices)[0]:\n",
    "                false_negatives.append({\n",
    "                    'id': meme_ids[idx],\n",
    "                    'prob': probs[idx].item(),\n",
    "                    'text': batch['text'][idx]\n",
    "                })\n",
    "    \n",
    "    # Display some examples\n",
    "    print(f\"Found {len(false_positives)} false positives and {len(false_negatives)} false negatives\")\n",
    "    \n",
    "    # Example: display a few false positives\n",
    "    print(\"\\nFalse Positive Examples:\")\n",
    "    for i, fp in enumerate(false_positives[:3]):\n",
    "        print(f\"ID: {fp['id']}, Confidence: {fp['prob']:.2f}, Text: {fp['text']}\")\n",
    "        # display_meme(test_df[test_df['id'] == fp['id']], 0, img_dir)\n",
    "    \n",
    "    # Example: display a few false negatives\n",
    "    print(\"\\nFalse Negative Examples:\")\n",
    "    for i, fn in enumerate(false_negatives[:3]):\n",
    "        print(f\"ID: {fn['id']}, Confidence: {fn['prob']:.2f}, Text: {fn['text']}\")\n",
    "        # display_meme(test_df[test_df['id'] == fn['id']], 0, img_dir)\n",
    "    \n",
    "    return false_positives, false_negatives\n",
    "\n",
    "# Example usage (not executed)\n",
    "# false_positives, false_negatives = analyze_errors(model, test_loader, '/path/to/images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflections\n",
    "\n",
    "### What Surprised Me\n",
    "\n",
    "Working through the Kaggle notebook on hateful meme detection revealed several surprising insights:\n",
    "\n",
    "1. **Multimodal Complexity**: The sheer complexity of multimodal reasoning required for this task was eye-opening. Models that performed well on either text-only or image-only classification often failed dramatically on multimodal inputs, highlighting how fundamentally different this problem is.\n",
    "\n",
    "2. **Clever Confounders**: The Facebook dataset was carefully designed with \"benign confounders\" — examples created specifically to fool unimodal approaches. A meme might contain text that seems hateful but paired with an innocent image that changes the context, or vice versa. This adversarial approach to dataset creation is a powerful way to ensure models learn true multimodal reasoning.\n",
    "\n",
    "3. **Context Dependence**: Many hateful memes require cultural, social, or historical knowledge to recognize their harmful content. This raises profound questions about how to build AI systems that understand context in the way humans do, beyond simple pattern matching.\n",
    "\n",
    "4. **Transfer Learning Effectiveness**: Despite the specialized nature of hateful meme detection, starting with pre-trained vision and language models proved remarkably effective. This suggests that general representations learned on large, diverse datasets can transfer well to specialized multimodal tasks with the right fine-tuning approach.\n",
    "\n",
    "### Scope for Improvement\n",
    "\n",
    "There are several promising directions for advancing hateful meme detection:\n",
    "\n",
    "1. **Advanced Fusion Mechanisms**: The notebook uses a relatively simple concatenation-based fusion approach. More sophisticated fusion techniques, such as cross-attention, co-attention, or transformer-based fusion, could better capture the complex interactions between modalities.\n",
    "\n",
    "2. **Incorporating External Knowledge**: Integrating external knowledge bases or large language models could help address the context-dependence problem, allowing models to access cultural, social, and historical information that might be necessary for accurate classification.\n",
    "\n",
    "3. **Explainability**: Developing better methods for model explainability is crucial for this sensitive task. Techniques that highlight which regions of an image and which words in the text contribute most to the hateful classification would not only improve model transparency but also help users understand why a particular decision was made.\n",
    "\n",
    "4. **Broader Dataset Coverage**: Current datasets, while valuable, can't possibly cover the full spectrum of hateful content. Continuously expanding and diversifying these datasets, particularly to include examples from different cultures and languages, would improve model robustness.\n",
    "\n",
    "5. **Active Learning Approaches**: Given the challenge of acquiring high-quality labeled data, active learning methods could help models identify the most informative examples to be labeled by human annotators, making the data collection process more efficient.\n",
    "\n",
    "6. **Human-in-the-Loop Systems**: Rather than aiming for fully automated moderation, developing systems where AI flags potential hateful content for human review might be a more practical approach that balances efficiency with accuracy.\n",
    "\n",
    "The hateful meme detection problem serves as a microcosm of broader challenges in AI: multimodal understanding, context-dependence, and ethical considerations around content moderation. Advances in this specific domain will likely contribute to improvements in multimodal learning more generally, with applications ranging from accessibility technologies to multimedia search and retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Papers\n",
    "\n",
    "1. Kiela, D., Firooz, H., Mohan, A., Goswami, V., Singh, A., Ringshia, P., & Testuggine, D. (2020). The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes. *Advances in Neural Information Processing Systems (NeurIPS)*, 33, 2611-2624.\n",
    "\n",
    "2. Pramanick, S., Sharma, S., Dimitrov, D., Akhtar, M. S., Nakov, P., & Chakraborty, T. (2021). MOMENTA: A Multimodal Framework for Detecting Harmful Memes and Their Targets. *Findings of the Association for Computational Linguistics: EMNLP 2021*, 4439-4455.\n",
    "\n",
    "3. Lu, J., Batra, D., Parikh, D., & Lee, S. (2019). ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks. *Advances in Neural Information Processing Systems (NeurIPS)*, 32, 13-23.\n",
    "\n",
    "4. Radford, A., Kim, J. W., Hallacy, C., Ramesh, A., Goh, G., Agarwal, S., ... & Sutskever, I. (2021). Learning Transferable Visual Models From Natural Language Supervision. *Proceedings of the 38th International Conference on Machine Learning (ICML)*, 8748-8763.\n",
    "\n",
    "### Code Repositories and Tools\n",
    "\n",
    "1. Alihan Sagoz's Kaggle Notebook: [Hateful Meme Detection](https://www.kaggle.com/code/alihansagoz/hateful-meme-detection)\n",
    "\n",
    "2. Facebook Research: [mmf - A modular framework for multimodal research](https://github.com/facebookresearch/mmf)\n",
    "\n",
    "3. Hugging Face Transformers: [Multimodal Models](https://huggingface.co/models?pipeline_tag=multimodal)\n",
    "\n",
    "4. PyTorch: [torchvision models](https://pytorch.org/vision/stable/models.html)\n",
    "\n",
    "### Datasets\n",
    "\n",
    "1. [Facebook Hateful Memes Challenge Dataset](https://ai.facebook.com/blog/hateful-memes-challenge-and-data-set/)\n",
    "\n",
    "2. [MEMOTION: Multimodal Twitter Dataset for Emoji Prediction](https://www.kaggle.com/datasets/ritresearch/memotion-dataset-7k)\n",
    "\n",
    "### Blogs and Articles\n",
    "\n",
    "1. Facebook AI Blog: [The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes](https://ai.facebook.com/blog/hateful-memes-challenge-and-data-set/)\n",
    "\n",
    "2. Towards Data Science: [Multimodal Deep Learning](https://towardsdatascience.com/multimodal-deep-learning-ce7d1d994f4)\n",
    "\n",
    "3. Berkeley AI Research Blog: [Visual Haystacks](https://bair.berkeley.edu/blog/2024/07/20/visual-haystacks/)\n",
    "\n",
    "### Tools Used\n",
    "\n",
    "1. Python Libraries: PyTorch, Transformers (Hugging Face), pandas, matplotlib, scikit-learn\n",
    "2. Jupyter Notebook for analysis and experimentation\n",
    "3. Pre-trained Models: ResNet-50, BERT, RoBERTa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}